Human Motion Trajectory Classifier (LSTM)

0. Setup and Run Manual (Quickstart)

Step 1. Environment Setup

It is recommended to use a virtual environment (Conda or venv) to avoid dependency conflicts.

conda create -n gipsy_lstm python=3.8
conda activate gipsy_lstm
pip install torch numpy scikit-learn scipy matplotlib


Step 2. Ensure Project Structure

This project relies on a shared data directory structure. Ensure your repository looks like this:

ML25_Gipsy/
├── data/
│   └── processed/
│       └── dataset1+2_raw.pkl   # [Required] Pre-processed Data from Team
└── LSTM/                        # [Current Working Directory]
    ├── preprocessing.py         # Data Loading (Pickle) & Augmentation
    ├── model_definition.py      # LSTM Model Architecture
    ├── model_training.py        # Training & Evaluation Functions
    ├── main.py                  # Main Execution Script
    ├── classifier_test.py       # Testing Script
    └── README.md


Step 3. Check Data File

The model loads data from the Pickle (.pkl) file generated by the team's data loader.
Ensure that dataset1+2_raw.pkl exists in ../data/processed/.

Step 4. Run Training Pipeline

Navigate to the LSTM directory and run the training script:

cd LSTM
python main.py


This will:

Load the pre-processed data (.pkl).

Apply Butterworth Low-pass Filter for noise removal.

Apply Online Data Augmentation (Jittering/Scaling).

Train the Bidirectional LSTM model.

Save the best model weights as best_model.pt.

Step 5. Run Testing

To evaluate the trained model on the held-out test set:

python classifier_test.py --model_path best_model.pt


1. Dataset

Input: End Effector Position (X, Y, Z in millimeters).

Source: ../data/processed/dataset1+2_raw.pkl.

Format: A dictionary containing raw sequences, labels, and class mappings.

Preprocessing:

Filtering: A Butterworth Low-pass Filter (Cutoff 3.0Hz) is applied after loading to remove high-frequency sensor noise.

Padding: Since motion trajectories have variable lengths, sequences are padded to match the longest sequence in the batch using PyTorch's pad_sequence.

2. Pipeline Overview

Step 1. Load & Preprocess

Loads the .pkl file containing aggregated data from multiple sessions.

Applies signal filtering to smooth the trajectory.

Splits data into Train (70%), Validation (15%), and Test (15%) sets using a fixed random seed.

Step 2. Data Augmentation (Online)

To address the small dataset size challenge, we apply augmentation on-the-fly during the training phase. This ensures the model sees a slightly different variation of the trajectory every epoch.

Jittering: Adds Gaussian noise ($\mu=0, \sigma=0.03$) to simulate sensor instability.

Scaling: Multiplies trajectories by a random factor ($0.95 \sim 1.05$) to simulate different arm sizes/ranges.

Step 3. Feature Engineering (LSTM)

Model: Bidirectional LSTM (Long Short-Term Memory).

Input: Raw 3D coordinates (x, y, z).

Logic: The model captures temporal dependencies and sequential patterns in both forward and backward directions, which is crucial for distinguishing geometric shapes.

Step 4. Classification

The final hidden states of the LSTM are passed through a Fully Connected Layer to classify the motion into one of the target categories (e.g., Circle, Vertical).

3. Usage

Configuration

You can modify hyperparameters directly in the CONFIGURATION section of main.py:

DATA_PATH = "../data/processed/dataset1+2_raw.pkl"
EPOCHS = 200
BATCH_SIZE = 16
HIDDEN_SIZE = 64


Testing

Ensure best_model.pt exists before running the test script.

python classifier_test.py --model_path best_model.pt


4. Code Structure

The project is modularized for explainability and maintenance:

preprocessing.py

load_data(pkl_path): Loads sequences and labels from the Pickle file.

DataAugmenter: Implements Jittering and Scaling logic.

butter_lowpass_filter: Signal processing for noise removal.

SensorDataset: Custom PyTorch Dataset class.

model_definition.py

SensorLSTM: Defines the neural network architecture (Bi-LSTM + Dropout + FC).

model_training.py

train_one_epoch(): Handles the training loop and backpropagation.

evaluate(): Computes loss and accuracy for validation/testing.

main.py

Orchestrates the entire training pipeline.

Handles data splitting and model saving.

classifier_test.py

Loads the saved model.

Performs final evaluation on the separated Test Set.

Outputs a detailed classification report.

5. Example Output

Training:

Using device: cpu
Loading data from ../data/processed/dataset1+2_raw.pkl...
Successfully loaded 62 sequences.
Classes: {'circle': 0, 'diagonal_left': 1, ...}

Starting Training...
Epoch 1/200 | Train Loss: 1.5992 Acc: 0.2791 | Val Loss: 1.4957 Acc: 0.4444
...
Epoch 200/200 | Train Loss: 0.0013 Acc: 1.0000 | Val Loss: 0.0300 Acc: 1.0000
Training Finished. Best Validation Accuracy: 1.0000


Testing:

Final Test Accuracy: 1.0000

Classification Report:
                precision    recall  f1-score   support

        circle       1.00      1.00      1.00         3
    horizontal       1.00      1.00      1.00         1
      vertical       1.00      1.00      1.00         2
      ...


6. Why LSTM? (Methodology Explanation)

1. Robustness to Sequential Data

Unlike traditional machine learning models (e.g., Random Forest or Decision Trees) that often require fixed-length feature vectors or resampling, LSTMs naturally handle variable-length time-series data. This allows us to preserve the temporal integrity of the motion without lossy aggregation.

2. Bidirectional Context

Motion trajectories have a geometric shape where the "start" and "end" context matters significantly. We utilize a Bidirectional LSTM, which processes the data from start-to-end and end-to-start simultaneously. This improves the model's ability to distinguish similar shapes (e.g., distinguishing a 'Vertical' line drawn up-to-down vs down-to-up) compared to unidirectional models.

3. Noise Robustness

By combining Low-pass Filtering (Preprocessing) and Online Data Augmentation (Training), our model is designed to be robust against sensor noise. Even with significant jitter or speed variations, the LSTM focuses on the global pattern of the movement rather than local outliers.

7. Troubleshooting

FileNotFoundError: Pickle file not found: Ensure that the team has run data_loader.py and the file dataset1+2_raw.pkl exists in the ../data/processed/ directory.

ModuleNotFoundError: Ensure all python files (preprocessing.py, model_definition.py, etc.) are in the same directory.

Low Accuracy: Try increasing EPOCHS in main.py (e.g., 200) to allow sufficient convergence for small datasets.